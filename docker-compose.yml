services:
  django:
    container_name: django
    build:
      context: .
      args:
        DJANGO_SECRET_KEY: ${DJANGO_SECRET_KEY} 
    command: >
      sh -c "python manage.py collectstatic --noinput &&
             python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - ./db.sqlite3:/app/db.sqlite3
    environment:
      REDIS_URL: ${REDIS_URL} 
      REDIS_HOST: ${REDIS_HOST}
      REDIS_PORT: ${REDIS_PORT}
      REDIS_DB: ${REDIS_DB}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_HOST: postgres
      DB_PORT: ${DB_PORT}
    env_file: 
      - .env
    restart: always
    depends_on:
      - postgres
      - redis

  # DATA STORAGE AND CACHING
  postgres:
    container_name: postgres
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    env_file:
      - .env
    restart: always
    
  redis:
    container_name: redis
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always

  # TASK SCHEDULING
  qcluster:
    container_name: qcluster
    build: .
    command: python manage.py qcluster
    ports: []
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
    restart: always

  # celery_worker:
  #   container_name: celery
  #   build:
  #     context: .
  #     args:
  #       REDIS_STREAMS_URL: ${REDIS_STREAMS_URL}
  #   command: python -m celery -A settings worker -l INFO
  #   ports: []
  #   volumes:
  #     - .:/app
  #   environment:
  #     CELERY_BROKER_URL: ${REDIS_STREAMS_URL}  # Redis Streams for broker
  #     CELERY_RESULT_BACKEND: ${DB_URL}         # PostgreSQL for result storage
  #   env_file:
  #     - .env
  #   depends_on:
  #     - redis
  #   restart: always

  # celery_beat:
  #   container_name: celery-beat
  #   build:
  #     context: .
  #     args:
  #       DJANGO_SECRET_KEY: ${DJANGO_SECRET_KEY} 
  #   command: celery -A settings beat -l info
  #   volumes:
  #     - .:/app
  #   environment:
  #     REDIS_STREAMS_URL: ${REDIS_STREAMS_URL}
  #     CELERY_RESULT_BACKEND: ${DB_URL}
  #   depends_on:
  #     - django
  #     - redis
  #   restart: always

  # MONITORING
  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    restart: always

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana
    restart: always
    environment:
      - GF_LOG_LEVEL=warn
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_SECURITY_ADMIN_PASSWORD}
    
  postgres-exporter:
    container_name: postgres-exporter
    image: bitnami/postgres-exporter:latest
    ports:
      - "9187:9187"
    env_file:
      - .env
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DB_HOST}:${DB_PORT}/${POSTGRES_DB}?sslmode=disable"
    depends_on:
      - postgres

  # flower:
  #   container_name: flower
  #   image: mher/flower:latest
  #   command: >
  #     flower --port=5555 --broker=${REDIS_STREAMS_URL}
  #   ports:
  #     - "5555:5555"
  #   environment:
  #     - CELERY_BROKER_URL=${REDIS_STREAMS_URL}
  #   restart: always
  #   depends_on:
  #     - redis
  #     - celery_worker

volumes:
  grafana_data:
  postgres_data:
  redis_data: