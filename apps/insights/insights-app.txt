
==== tasks.py ====

==== data_pipeline.py ====
"""
Title: Data Pipeline for CSV Processing and LLM Integration
Description:
This script orchestrates the data pipeline for processing GA4 CSV data.
It validates, cleans, filters, and generates statistical overviews,
and optionally integrates with an LLM for dataset summaries.

Usage:
Run this file directly to execute the pipeline:
    python -m apps.insights.data_pipeline
"""

import logging
import os
import pandas as pd
from apps.insights.services.csv_processor import CSVProcessor
from apps.insights.services.openai.summary_generator import generate_summary

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


def run_pipeline(file_path: str, start_date: str):
    """
    Orchestrates the CSV processing pipeline and outputs results.
    Args:
        file_path (str): Path to the CSV file.
        start_date (str): Starting date for data filtering (YYYY-MM-DD).
    """
    try:
        logging.info("Initializing CSVProcessor...")
        processor = CSVProcessor(file_path)

        logging.info("Starting the CSV processing pipeline...")
        # Process the file: load, validate, clean, and filter data
        processor.load()
        processor.validate()
        processor.clean()
        week1_df, week2_df = processor.filter(start_date)

        # Calculate week date ranges
        start_date_dt = pd.to_datetime(start_date)
        week1_start = start_date_dt
        week1_end = week1_start + pd.Timedelta(days=6)
        week2_start = week1_end + pd.Timedelta(days=1)
        week2_end = week2_start + pd.Timedelta(days=6)

        # Generate statistical overviews
        logging.info("Generating statistical overviews...")
        logging.info(
            f"\nStatistical Overview - Week 1 (Start: {week1_start.date()}, End: {week1_end.date()}):"
        )
        print(week1_df.describe().to_string())

        logging.info(
            f"\nStatistical Overview - Week 2 (Start: {week2_start.date()}, End: {week2_end.date()}):"
        )
        print(week2_df.describe().to_string())

        # LLM Integration
        logging.info("Generating summaries with OpenAI...")

        week1_summary = week1_df.describe().to_string()
        week2_summary = week2_df.describe().to_string()

        week1_llm_summary = generate_summary(week1_summary)
        week2_llm_summary = generate_summary(week2_summary)

        logging.info(
            f"\nLLM Summary - Week 1 ({week1_start.date()} to {week1_end.date()}):"
        )
        print(week1_llm_summary.dataset_summary)
        logging.info("Key Metrics:")
        for metric in week1_llm_summary.key_metrics:
            print(f"{metric.name}: {metric.value} ({metric.description})")

        logging.info(
            f"\nLLM Summary - Week 2 ({week2_start.date()} to {week2_end.date()}):"
        )
        print(week2_llm_summary.dataset_summary)
        logging.info("Key Metrics:")
        for metric in week2_llm_summary.key_metrics:
            print(f"{metric.name}: {metric.value} ({metric.description})")

        logging.info("Pipeline executed successfully!")

    except Exception as e:
        logging.error(f"Pipeline failed: {e}")
        raise


if __name__ == "__main__":
    # Dynamically resolve the path to the CSV file
    current_dir = os.path.dirname(os.path.abspath(__file__))
    csv_file_path = os.path.join(
        current_dir, "data/ga4_data.csv"
    )  # Path inside insights
    start_date = "2024-01-01"  # Set your start date
    run_pipeline(csv_file_path, start_date)

==== dump.txt ====

==== __init__.py ====

==== apps.py ====
from django.apps import AppConfig


class InsightsConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "apps.insights"

==== dump_project.py ====
import os

output_file = "dump.txt"
exclude_dir = "./env"
file_types = (".py", ".js", ".css", ".html", ".yaml", ".json", ".conf", ".txt")

with open(output_file, "w") as out:
    for root, dirs, files in os.walk("."):
        # Exclude the env directory and its subdirectories
        dirs[:] = [d for d in dirs if os.path.join(root, d) != exclude_dir]

        for file in files:
            if file.endswith(file_types):
                file_path = os.path.join(root, file)
                out.write(f"\n==== {file} ====\n")
                with open(file_path, "r", encoding="utf-8") as f:
                    out.write(f.read())

==== admin.py ====
# apps/insights/admin.py
from django.contrib import admin
from .models import DataSummary
from .forms.admin import DataSummaryAdminForm


@admin.register(DataSummary)
class DataSummaryAdmin(admin.ModelAdmin):
    form = DataSummaryAdminForm
    list_display = ("label",)
    search_fields = ("label",)

==== tests.py ====
from django.test import TestCase

# Create your tests here.

==== views.py ====
from django.shortcuts import render

# Create your views here.

==== __init__.py ====

==== 0001_initial.py ====
# Generated by Django 5.1.3 on 2024-11-23 13:12

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='DataSummary',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('label', models.CharField(help_text="A label identifying the dataset (e.g., 'Week 1').", max_length=50)),
                ('plain_summary', models.TextField(help_text='An English summary of the dataset.')),
                ('key_metrics', models.JSONField(help_text='Structured key metrics from the dataset.')),
                ('metadata', models.JSONField(blank=True, help_text='Additional metadata about the summary (e.g., filters applied).', null=True)),
            ],
            options={
                'verbose_name': 'Data Summary',
                'verbose_name_plural': 'Data Summaries',
            },
        ),
    ]

==== __init__.py ====

==== admin.py ====
# app/insights/forms/admin.py
from django import forms


class DataSummaryAdminForm(forms.ModelForm):
    start_date = forms.DateField(
        widget=forms.widgets.DateInput(attrs={"type": "date"}),
        required=False,
        help_text="Select a start date for the analysis.",
    )

==== test_summary_generator.py ====
import pandas as pd
from apps.insights.services.openai.summary_generator import generate_summary


def test_summary_generator():
    """
    Tests the generate_summary function with a Pandas statistical summary.
    """
    # Create a sample DataFrame
    data = {
        "Sales": [100, 200, 300, 400, 500],
        "Profit": [20, 50, 70, 100, 150],
        "Expenses": [80, 150, 230, 300, 350],
    }
    df = pd.DataFrame(data)

    # Generate the Pandas statistical summary
    pandas_summary = df.describe().to_string()

    print("\nPandas Statistical Summary:")
    print(pandas_summary)

    # Generate the LLM-based summary
    try:
        result = generate_summary(pandas_summary)

        print("\nGenerated LLM Summary:")
        print(result.dataset_summary)

        print("\nKey Metrics:")
        for metric in result.key_metrics:
            print(f"- {metric.name}: {metric.value} ({metric.description})")

    except Exception as e:
        print(f"Error during summary generation: {e}")


if __name__ == "__main__":
    test_summary_generator()

==== __init__.py ====
from .summary import DataSummary

__all__ = ["DataSummary"]

==== summary.py ====
# apps/insights/models/summary.py
from django.db import models

# Uncomment the necessary mixins once their import paths are fixed
# from apps.common.behaviors.timestampable import Timestampable  # Adds created_at and updated_at fields
# from apps.common.behaviors.uuidable import UUIDable  # Adds a UUID primary key field
# from apps.common.behaviors.annotatable import Annotatable  # Adds annotation capabilities
# from apps.common.behaviors.authorable import Authorable  # Adds an author field linked to User


# Model representing a summary of a dataset with key metrics and a description.
class DataSummary(
    models.Model
):  # Add Uuidable mixin, Timestampable, Annotatable, Authorable

    # Short label for the dataset
    label = models.CharField(
        max_length=50,
        help_text="A label identifying the dataset (e.g., 'Week 1').",
    )

    # Text summary generated by ChatGPT
    plain_summary = models.TextField(help_text="An English summary of the dataset.")

    # Key metrics in JSON format
    key_metrics = models.JSONField(help_text="Structured key metrics from the dataset.")

    # Optional metadata
    metadata = models.JSONField(
        null=True,
        blank=True,
        help_text="Additional metadata about the summary (e.g., filters applied).",
    )

    def __str__(self):
        return f"DataSummary: {self.label}"

    class Meta:
        # ordering = ["-created_at"]  # Order by most recently created
        verbose_name = "Data Summary"
        verbose_name_plural = "Data Summaries"

==== csv_processor.py ====
# apps/insights/services/csv_processor.py
import logging
from .csv.csv_reader import load_csv
from .csv.data_validator import validate_columns
from .csv.data_cleaner import clean_data
from .csv.data_filter import filter_data
from .csv.data_overview import generate_overview

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


class CSVProcessor:
    def __init__(self, file_path: str):
        """
        Initialize the CSVProcessor with the path to the CSV file.
        """
        self.file_path = file_path
        self.df = None  # Placeholder for the loaded DataFrame

    def load(self):
        """
        Load the CSV file into a Pandas DataFrame.
        """
        logging.info("Loading CSV...")
        self.df = load_csv(self.file_path)

    def validate(self):
        """
        Validate that the CSV contains all required columns.
        """
        logging.info("Validating CSV columns...")
        validate_columns(self.df)

    def clean(self):
        """
        Clean the DataFrame by standardizing and formatting columns.
        """
        logging.info("Cleaning data...")
        self.df = clean_data(self.df)

    def filter(self, start_date: str):
        """
        Filter the data into two weeks based on the start date.
        """
        logging.info("Filtering data into Week 1 and Week 2...")
        return filter_data(self.df, start_date)

    def generate_overviews(self, week1_df, week2_df):
        """
        Generate statistical overviews for the filtered DataFrames.
        """
        logging.info("Generating statistical overviews...")
        generate_overview(week1_df, "Week 1")
        generate_overview(week2_df, "Week 2")

    def process(self, start_date: str):
        try:
            self.load()
            self.validate()
            self.clean()
            week1_df, week2_df = self.filter(start_date)
            self.generate_overviews(week1_df, week2_df)
        except ValueError as e:
            logging.error(f"Processing error: {e}")
            raise

==== __init__.py ====

==== data_overview.py ====
# apps/insights/services/csv/data_overview.py


def generate_overview(df, label):
    # Generate and print statistical overview for the given DataFrame
    print(f"\nStatistical Overview - {label}:")
    print(df.describe())

==== data_validator.py ====
# apps/insights/services/csv/data_validator.py
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

REQUIRED_COLUMNS = {
    "date",
    "source",
    "sessions",
    "users",
    "new_users",
    "pageviews",
    "pages_per_session",
    "avg_session_duration",
    "bounce_rate",
    "conversion_rate",
    "transactions",
    "revenue",
}


def validate_columns(df):
    # Check for missing required columns
    missing_columns = REQUIRED_COLUMNS - set(df.columns)
    if missing_columns:
        raise ValueError(f"Missing required columns: {', '.join(missing_columns)}")
    logging.info("All required key columns are present.")

==== data_filter.py ====
# apps/insights/services/csv/data_filter.py
import pandas as pd
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


def filter_data(df, start_date):
    """
    Filter the DataFrame into two weeks based on the start_date.

    Args:
        df (pd.DataFrame): Input DataFrame to filter.
        start_date (str): Start date for filtering (YYYY-MM-DD).

    Returns:
        tuple: Two DataFrames (Week 1, Week 2).
    """
    logging.info("Filtering data for organic traffic...")
    organic_df = df[df["source"] == "organic"]
    if organic_df.empty:
        raise ValueError("No data found for organic traffic.")

    # Define date ranges
    logging.info(f"Calculating date ranges from start_date: {start_date}")
    start_date = pd.to_datetime(start_date)
    end_date_week1 = start_date + pd.Timedelta(days=6)  # Week 1 range
    start_date_week2 = start_date + pd.Timedelta(days=7)  # Week 2 range
    end_date_week2 = start_date + pd.Timedelta(days=13)  # Week 2 range end

    # Filter Week 1
    logging.info(f"Filtering Week 1: {start_date.date()} to {end_date_week1.date()}")
    week1_df = organic_df[
        (organic_df["date"] >= start_date) & (organic_df["date"] <= end_date_week1)
    ]
    if week1_df.empty:
        raise ValueError("No data found for Week 1.")

    # Log filtered Week 1 data
    logging.info(f"Week 1 Data (Rows: {len(week1_df)}):\n{week1_df}")

    # Filter Week 2
    logging.info(
        f"Filtering Week 2: {start_date_week2.date()} to {end_date_week2.date()}"
    )
    week2_df = organic_df[
        (organic_df["date"] >= start_date_week2)
        & (organic_df["date"] <= end_date_week2)
    ]
    if week2_df.empty:
        raise ValueError("No data found for Week 2.")

    # Log filtered Week 2 data
    logging.info(f"Week 2 Data (Rows: {len(week2_df)}):\n{week2_df}")

    return week1_df, week2_df

==== csv_reader.py ====
# apps/insights/services/csv/csv_reader.py
import pandas as pd  # Missing import added


def load_csv(file_path: str) -> pd.DataFrame:
    """
    Load a CSV file into a Pandas DataFrame.

    Args:
        file_path (str): Path to the CSV file.

    Returns:
        pd.DataFrame: Loaded data.
    """
    try:
        df = pd.read_csv(file_path)
        print(
            f"Successfully loaded {file_path}: {len(df)} rows, {len(df.columns)} columns"
        )
        return df
    except Exception as e:
        raise ValueError(f"Error loading CSV file: {e}")

==== __init__.py ====

==== data_cleaner.py ====
# apps/insights/services/csv/data_cleaner.py
import pandas as pd
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


# Detect the date column dynamically
def detect_date_column(df):
    date_columns = [col for col in df.columns if "date" in col.lower()]
    if len(date_columns) == 0:
        raise ValueError("No date column detected in the dataset.")
    if len(date_columns) > 1:
        raise ValueError(f"Multiple possible date columns found: {date_columns}")
    logging.info(f"Date column detected: {date_columns[0]}")
    return date_columns[0]


# Standardize the format of the date column
def standardize_date_format(df, date_column):
    try:
        df[date_column] = pd.to_datetime(df[date_column], errors="coerce")
        if df[date_column].isna().any():
            raise ValueError(f"Invalid or unparseable dates in column '{date_column}'.")
        df[date_column] = df[date_column].dt.strftime("%Y-%m-%d")
        logging.info(
            f"Dates standardized to 'YYYY-MM-DD' format in column '{date_column}'."
        )
        return df
    except Exception as e:
        raise ValueError(f"Error standardizing date column: {e}")


# Ensure date column is in datetime format for filtering
def ensure_datetime_format(df, date_column):
    try:
        df[date_column] = pd.to_datetime(df[date_column], errors="coerce")
        if df[date_column].isna().any():
            raise ValueError(f"Invalid or unparseable dates in column '{date_column}'.")
        logging.info(f"Date column '{date_column}' converted to datetime format.")
        return df
    except Exception as e:
        raise ValueError(f"Error ensuring datetime format: {e}")


# Perform the full data cleaning process
def clean_data(df):
    date_column = detect_date_column(df)
    df = standardize_date_format(df, date_column)
    df = ensure_datetime_format(df, date_column)
    return df

==== summary_generator.py ====
# apps/insights/services/openai/summary_generator.py
from decouple import config
from instructor import from_openai
from openai import OpenAI
from .schemas import SummaryOutput
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

# Load OpenAI API key
openai_api_key = config("OPENAI_API_KEY")

# Initialize OpenAI client
client = from_openai(OpenAI(api_key=openai_api_key))


def generate_summary(statistical_summary: str) -> SummaryOutput:
    """
    Generates a structured dataset summary using OpenAI API.

    Args:
        statistical_summary (str): Statistical summary of the dataset.

    Returns:
        SummaryOutput: A structured summary containing dataset insights and key metrics.
    """
    prompt = f"""
    The following is a statistical summary of a dataset:

    {statistical_summary}

    Please:
    1. Write a concise plain English summary of the dataset.
    2. Highlight the key metrics in a structured format.
    """
    try:
        logging.info("Requesting dataset summary from OpenAI...")

        # API call with structured output validation
        response = client.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[{"role": "user", "content": prompt}],
            response_model=SummaryOutput,
        )

        logging.info("Successfully received structured response.")
        return response

    except client.ValidationError as e:
        logging.error(f"Validation error: {e}")
        raise ValueError(f"Validation error: {e}")

    except client.ApiError as e:
        logging.error(f"API error: {e}")
        raise ValueError(f"API error: {e}")

    except Exception as e:
        logging.error(f"Unexpected error: {e}")
        raise ValueError(f"Unexpected error: {e}")

==== __init__.py ====

==== llm_integration.py ====
# apps/insights/services/openai/llm_integration.py
from decouple import config
import instructor
from openai import OpenAI
from typing import List
from .schemas import SummaryOutput  # Import the updated SummaryOutput model

# Load the OpenAI API key from environment variables
openai_api_key = config("OPENAI_API_KEY")

# Initialize OpenAI client with Instructor
client = instructor.from_openai(OpenAI(api_key=openai_api_key))


def generate_summary(statistical_summary: str) -> SummaryOutput:
    """
    Generates a structured dataset summary using the OpenAI API.

    Args:
        statistical_summary (str): The statistical summary of the dataset.

    Returns:
        SummaryOutput: The structured output containing a dataset summary and key metrics.
    """
    prompt = f"""
    The following is a statistical summary of a dataset:

    {statistical_summary}

    Please:
    1. Write a concise summary of the dataset.
    2. Highlight the key metrics.
    """
    try:
        # Make the API call
        response = client.chat.completions.create(
            model="gpt-4o-2024-08-06",
            messages=[{"role": "user", "content": prompt}],
            response_model=SummaryOutput,  # Use the updated SummaryOutput model for validation
        )
        return response

    except instructor.ValidationError as e:
        raise ValueError(f"Validation Error: {e}")

    except instructor.ApiError as e:
        raise ValueError(f"API Error: {e}")

    except Exception as e:
        raise ValueError(f"Unexpected Error: {e}")

==== schemas.py ====
# apps/insights/services/openai/schemas.py
from pydantic import BaseModel, Field, ValidationError
from typing import List


class KeyMetric(BaseModel):
    """
    Represents a single key metric extracted from the dataset summary.
    """

    name: str
    value: float
    description: str

    @classmethod
    def ordered_metrics(cls) -> List["KeyMetric"]:
        """
        Defines the exact order and expected names for key metrics.
        """
        return [
            cls(
                name="Average Sessions",
                value=0,
                description="The mean number of sessions per day.",
            ),
            cls(
                name="Average Users",
                value=0,
                description="The mean number of users per day.",
            ),
            cls(
                name="Average New Users",
                value=0,
                description="The mean number of new users per day.",
            ),
            cls(
                name="Average Pageviews",
                value=0,
                description="The mean number of pageviews per day.",
            ),
            cls(
                name="Average Pages per Session",
                value=0,
                description="The average number of pages viewed per session.",
            ),
            cls(
                name="Average Session Duration",
                value=0,
                description="The average duration of a session in seconds.",
            ),
            cls(
                name="Bounce Rate",
                value=0,
                description="The average percentage of visitors who leave the site after viewing only one page.",
            ),
            cls(
                name="Conversion Rate",
                value=0,
                description="The average percentage of visitors who completed a desired action.",
            ),
            cls(
                name="Average Transactions",
                value=0,
                description="The mean number of transactions per day.",
            ),
            cls(
                name="Average Revenue",
                value=0,
                description="The average revenue generated per day.",
            ),
        ]

    def validate_name(self) -> bool:
        """
        Ensures that the name of the metric matches one of the expected names.
        """
        expected_names = [metric.name for metric in self.ordered_metrics()]
        if self.name not in expected_names:
            raise ValueError(f"Unexpected metric name: {self.name}")
        return True


class SummaryOutput(BaseModel):
    """
    Structured output for a dataset summary response from the LLM.
    """

    dataset_summary: str = Field(
        ..., description="A concise English summary of the dataset."
    )
    key_metrics: List[KeyMetric] = Field(
        ..., description="List of key metrics extracted from the dataset."
    )

    def enforce_ordered_metrics(self):
        """
        Enforces that key metrics are in the exact order defined by `KeyMetric.ordered_metrics`.
        """
        ordered_names = [metric.name for metric in KeyMetric.ordered_metrics()]
        self.key_metrics = sorted(
            self.key_metrics,
            key=lambda metric: (
                ordered_names.index(metric.name)
                if metric.name in ordered_names
                else float("inf")
            ),
        )
        # Ensure no unexpected metrics
        for metric in self.key_metrics:
            metric.validate_name()
